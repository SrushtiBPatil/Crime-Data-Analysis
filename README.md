<<<<<<< HEAD
# 🔍 Crime Hotspot Analysis Using Clustering (Los Angeles Crime Data)

This project applies unsupervised machine learning techniques to identify spatial crime hotspots in Los Angeles using a large-scale dataset (`Crime_Data_from_2020_to_Present.csv`). We implement and compare **KMeans** and **Agglomerative Clustering** algorithms, evaluate their performance using **Silhouette Scores**, and visualize crime patterns through scatter plots and dashboards. This project follows the **CRISP-DM** methodology and includes data cleaning, feature engineering, modeling, and evaluation.

---

## 📁 Project Structure



---

## 📊 Tools & Technologies Used

- Python 3.10
- pandas, numpy
- matplotlib, seaborn
- scikit-learn
- Power BI (for dashboards)
- Google Colab (execution environment)

---
## 📥 Dataset Source

> 📂 [Crime Data from 2020 to Present – data.lacity.org](https://data.lacity.org/Public-Safety/Crime-Data-from-2020-to-Present/2nrs-mtv8)

Note: Due to GitHub's file size limitations, the full dataset is not included in this repo. You can download it manually from the link above.

---

## 🚀 Features

- ✅ Spatial clustering with KMeans and Agglomerative methods  
- ✅ Silhouette score–based model evaluation  
- ✅ Temporal trend analysis using datetime features  
- ✅ Interactive dashboards (Power BI)  
- ✅ Well-documented code and final report  

---

## 🧠 CRISP-DM Workflow Followed

1. **Business Understanding** – Identify hotspots for policing resource optimization  
2. **Data Understanding** – Explore raw dataset and patterns  
3. **Data Preparation** – Clean, normalize, and sample data  
4. **Modeling** – Apply KMeans and Agglomerative Clustering  
5. **Evaluation** – Compare models using Silhouette Score and visualizations  
6. **Deployment** – Share results through report, dashboard, and GitHub  

---

## 📥 Dataset Source

> 📂 Crime Data from 2020 to Present – [data.lacity.org](https://data.lacity.org)

Due to size constraints, only a **20,000-row sample** is used for clustering. You may download the full dataset manually.

---

## 📝 How to Run

1. Clone this repository:
```bash
git clone https://github.com/SrushtiBPatil/Crime-Data-Analysis.git
cd Crime-Data-Analysis

2. pip install -r requirements.txt

3. Run the notebook:

Open notebooks/Group11_Model_implementation.ipynb in Jupyter/Colab.
